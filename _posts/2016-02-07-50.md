---
layout: post
title:	"Give an example of a specific, well-studied neuronal microcircuit and describe how it performs a specific calculation."
date:	2016-02-07
category:	"neural-networks-and-coding"
---
## Answer

I'll be describing the circuit that gives rives to ON-center
retinal ganglion cells (RGCs) and then tracing that up to visual cortex
(skipping the thalamus, *pace* Sherman),
where I'll describe how the output of this circuit is used to construct
the simple cells of
[Hubel and Wiesel]({{site.baseurl}}/92vii).

### Retinal Circuitry

The basic retinal circuit appears below.

Red arrows represent sign-preserving synapses,
while green arrows represent sign-inverting arrows.

![retinalCircuit_1]
{: style="text-align: center"}

At the top are the photoreceptors, which
[transduce light into electrical activity]({{site.baseurl}}/01).
To the frustration of neuroscience undergraduates
and medical students everywhere, there are two unintuitive things about photoreceptors.
First, they are at the back of the retina, behind a bunch of light-scattering tissue.
Second, their response to light is *hyperpolarization*, rather than depolarization,
as we've come to expect from other systems.

These cells, unlike your standard vertebrate neurons but much like
the neurons of invertebrates, do not fire
[action potentials]({{site.baseurl}}/23),
but rather continuously release neurotransmitter as an monotonic,
continuous function of the membrane potential: an analog signal.

Therefore light causes a decrease in neurotransmitter release.
These cells release glutamate, an excitatory neurotransmitter.
Again to the chagrin of the mnemonically-minded,
the bipolar cells express a
[metabotropic receptor]()
for glutamate, sometimes called an APB receptor,
sometimes called mGluR6
([see here for more details](http://webvision.med.utah.edu/book/part-v-phototransduction-in-rods-and-cones/glutamate-and-glutamate-receptors-in-the-vertebrate-retina/)).
This receptor happens to do the opposite of most glutamate receptors:
it decreases cation conductance.

So the connection from photoreceptors to bipolar cells is *sign-inverting*.
Excitation of a photoreceptor leads to inhibition of a bipolar cell.
This leads us to the awkward conclusion that photoreceptors are inhibited by light.
C'est la vie.

These bipolar cells, so-named for their symmetric shape,
synapse onto retinal ganglion cells.
Those who prefer forests to trees breathe a sigh of relief:
bipolar cells release glutamate onto retinal ganglion cells,
which express good-old-fashioned AMPA receptors
and fire classical action potentials.
Sign, and sanity, are preserved.

One more cell type makes an appearance,
all the way back up at the photoreceptor layer.
These are the "horizontal cells",
so named because they literally go against the grain,
making connections perpendicular to the "vertical"
circuit just described.
Horizontal cells receive input from a neighborhood of photoreceptors,
then synapse right back onto that same group.
They are also coupled by
[gap junctions]({{site.baseurl}}/31)(not pictured)
into a relatively synchronous, recurrent network.

This presentation of the retina is, in many ways, a simplification of the facts.
First, we're implicitly only discussing one of the simplest retinal circuits:
the cone-to-RGC pathway of the fovea, the highest acuity portion of the eye.
In the periphery, multiple inputs converge on single ganglion cells,
Furthermore, we've neglected starburst amacrine cells
and the direction-selective ganglion cells they support.
Glia, the perennially forgotten neural tissue, are neither seen nor heard.

We will ignore that complexity and focus in on our manageable chunk.
We will answer the question of "what does this piece do?"
and maybe get a glimpse of why it does that.

### The Retinal Computation

The net result of all of the circuitry described above
is best understood if we take it apart into two pieces.

First, we have the response of the photoreceptor.
Its response changes maximally when a light source is at some spot,
then falls off rapidly and symmetrically as the light source moves away.
This can be represented by a bell curve, or Gaussian function,
and appears in green below.
Note that we're only considering light moving on one dimension for now.

![retinalCircuit_2]
{: style="text-align: center"}

Second, we have the response of the nearby horizontal cells.
These cells aren't directly light sensitive,
but they pool or average the responses of the photoreceptors.
This gives them a weaker and broader response.
Their activity as a function of the position of the light source is shown in magenta.

A bipolar cell sees the difference of these two pieces,
a photoreceptor acting in opposition to its local horizontal inhibitory network.
This is represented by the green plus sign inside a circle.
The two magenta arrows have flat heads,
the international sign for "inhibitory connection".

The mathematical result of subtracting the three signals
appears in green below.
This shape is well-known to aficionados of signal processing,
especially image processing: it is the "Difference-of-Gaussians" or,
more colorfully but perhaps politically-incorrectly, the "Mexican Hat Wavelet".

This curve might be more familiar to neuroscientists when plotted differently.
Above, we used one axis for space and another for neural response.
If we plot both spatial dimensions and use color for neural response.
we get something more familiar:

![rgcRF]
{: style="text-align: center"}

I've pulled a little trick here and plotted response intensity as brightness,
which happens to result in the optimal stimulus for this cell --
what is called its "receptive field".
This is one of the many reasons why studying vision is easier than, say, somatosensation.

This 2-D Mexican Hat Wavelet (the sombrero now a bit harder to see) is
[moderately useful for image processing](http://fourier.eng.hmc.edu/e161/lectures/gradient/node9.html),
as can be seen in the processed image of a panda below.

![panda_DoG]
{: style="text-align: center"}

Though this image is less useful to the human eye,
it is an excellent representation for computation,
since it removes the correlations,
or first-order statistical content, of the image, resulting in a
[more efficient code](http://www.ncbi.nlm.nih.gov/pubmed/22149669).
This decreased redundancy allows for a more efficient transmission of information,
which has potential evolutionary advantages.

Fans of Shannon's Incompressibility Theorem may protest that no lossless code
can achieve this decrease in redundancy for every signal:
for every signal that you win on, there is another on which your code does worse.
They are correct: this process throws out some information; i.e. it is *lossy*.
However, the eyes of animals, unlike the files on computers, are not expected to store
arbitrary signals. Instead, they interact with a structured and consistent external environment,
and so they can adapt to that structure to increase efficiency.
Consider how much better you can remember, distinguish, and describe photographs than
the static that appears on old analog TV sets.

### One Step Further: Primary Visual Cortex

Many computations are performed in primary visual cortex (V1),
but the best-studied is still that discovered by
[Hubel and Wiesel]({{site.baseurl}}/92vii) in the 70s.

The inputs of several ganglion cells converge on a single cortical neuron.
This results in a receptive field for this neuron
that is the sum of the underlying receptive fields.

![simpleRFs]
{: style="text-align: center"}

**Fig. X** Simple cells concatenate retinal ganglion cell (RGC) responses.
The left panel shows the "receptive field" of an ON-center RGC.
It can be thought of as the stimulus that maximally excites the neuron.
The center panel shows the result of adding together three ON-center RGCs
with slightly shifted centers.
The right panel is a schematic of the necessary neural circuit,
simplified to the one-dimensional case.
Three neurons, purple, green, and dark blue, have ON-center receptive fields,
each with a slightly different center, shown above.
They provide excitatory input (arrows) to the sky blue simple cell.
Try drawing this cicruit yourself in two dimensions!

These receptive fields function as "edge detectors":
they are most activated by transitions between dark and light regions.
It is intuitively obvious that edge detection is important,
since edges are what delineate objects in a visual scene.

Less obviously, the decomposition of an image into edges
also reduces redunancy and removes correlations.
In fact, many algorithms designed to automatically discover
efficient representations of complex signals,
like sparse coding and independent component analysis,
converge on edge detection.

Check out
[this blog post]({{site.baseurl}}/09)
to follow this circuit down another step.

### A Coda on Complexity

The over-all effect of the above description may leave one feeling
that we understand quite a bit about the function of the visual system.
Unfortunately, this is not really the case.
One glaring example: we've discussed static images,
but eyes are designed to process dynamically changing input.

So: as exciting as the progress of neuroscience is,
we should always remember to be humble.
Even for V1, one of the better-understood and simpler parts of the brain,
we know what approximately
[15% of the tissue is doing](http://redwood.psych.cornell.edu/papers/olshausen_field_2004.pdf).

### References

* Kandel and Schwartz, 5e. _Low Level Visual Processing: The Retina_. Ch 5-26.

[retinalCircuit_1]: {{site.DBL}}/retinalCircuit_1.jpg
[retinalCircuit_2]: {{site.DBL}}/retinalCircuit_2.jpg
[rgcRF]: {{site.DBL}}/rgcRF.png
[panda_DoG]: {{site.DBL}}/panda_DoG.gif
[simpleRFs]: {{site.DBL}}/simpleRFs.png
